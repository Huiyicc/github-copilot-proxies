package copilot

import (
	_ "embed"
	"io"
	"log"
	"net/http"
	"time"

	"github.com/gin-gonic/gin"
)

type Pong struct {
	Now    int    `json:"now"`
	Status string `json:"status"`
	Ns1    string `json:"ns1"`
}

// GetPing 模拟ping接口
func GetPing(ctx *gin.Context) {
	ctx.JSON(http.StatusOK, Pong{
		Now:    time.Now().Second(),
		Status: "ok",
		Ns1:    "200 OK",
	})
}

// GetModels 获取模型列表
func GetModels(ctx *gin.Context) {
	ctx.JSON(http.StatusOK, gin.H{
		"data": []gin.H{
			{
				"capabilities": gin.H{
					"family": "gpt-3.5-turbo",
					"limits": gin.H{
						"max_context_window_tokens": 16384,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         12288,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true, "tool_calls": true},
					"tokenizer": "cl100k_base",
					"type":      "chat",
				},
				"id":                   "gpt-3.5-turbo",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT 3.5 Turbo",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-3.5-turbo-0613",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-3.5-turbo",
					"limits": gin.H{
						"max_context_window_tokens": 16384,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         12288,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true, "tool_calls": true},
					"tokenizer": "cl100k_base",
					"type":      "chat",
				},
				"id":                   "gpt-3.5-turbo-0613",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT 3.5 Turbo",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-3.5-turbo-0613",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4o-mini",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         12288,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4o-mini",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT-4o mini",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4o-mini-2024-07-18",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4o-mini",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         12288,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4o-mini-2024-07-18",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT-4o mini",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4o-mini-2024-07-18",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4",
					"limits": gin.H{
						"max_context_window_tokens": 32768,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         32768,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true, "tool_calls": true},
					"tokenizer": "cl100k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT 4",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4-0613",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4",
					"limits": gin.H{
						"max_context_window_tokens": 32768,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         32768,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true, "tool_calls": true},
					"tokenizer": "cl100k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4-0613",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT 4",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4-0613",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4-turbo",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         64000,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true},
					"tokenizer": "cl100k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4-0125-preview",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT 4 Turbo",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4-0125-preview",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4o",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         64000,
						"vision": gin.H{
							"max_prompt_image_size": 3145728,
							"max_prompt_images":     1,
							"supported_media_types": []string{"image/jpeg", "image/png", "image/webp", "image/gif"},
						},
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true, "vision": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4o",
				"is_chat_default":       true,
				"is_chat_fallback":      false,
				"model_picker_enabled":  true,
				"name":                  "GPT-4o",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4o-2024-11-20",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4o",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         16384,
						"max_prompt_tokens":         64000,
						"vision": gin.H{
							"max_prompt_image_size": 3145728,
							"max_prompt_images":     1,
							"supported_media_types": []string{"image/jpeg", "image/png", "image/webp", "image/gif"},
						},
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true, "vision": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4o-2024-11-20",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT-4o",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4o-2024-11-20",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4o",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         64000,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4o-2024-05-13",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT-4o",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4o-2024-05-13",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4o",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         4096,
						"max_prompt_tokens":         64000,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4-o-preview",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT-4o",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4o-2024-05-13",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4o",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         16384,
						"max_prompt_tokens":         64000,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4o-2024-08-06",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT-4o",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4o-2024-08-06",
			},
			{
				"capabilities": gin.H{
					"family": "o3-mini",
					"limits": gin.H{
						"max_context_window_tokens": 200000,
						"max_output_tokens":         100000,
						"max_prompt_tokens":         64000,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true, "structured_outputs": true, "tool_calls": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "o3-mini",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  true,
				"name":                  "o3-mini",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "o3-mini-2025-01-31",
			},
			{
				"capabilities": gin.H{
					"family": "o3-mini",
					"limits": gin.H{
						"max_context_window_tokens": 200000,
						"max_output_tokens":         100000,
						"max_prompt_tokens":         64000,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true, "structured_outputs": true, "tool_calls": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "o3-mini-2025-01-31",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "o3-mini",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "o3-mini-2025-01-31",
			},
			{
				"capabilities": gin.H{
					"family": "o3-mini",
					"limits": gin.H{
						"max_context_window_tokens": 200000,
						"max_output_tokens":         100000,
						"max_prompt_tokens":         64000,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true, "structured_outputs": true, "tool_calls": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "o3-mini-paygo",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "o3-mini",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "o3-mini-paygo",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4o-mini",
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true},
					"tokenizer": "o200k_base",
					"type":      "completion",
				},
				"id":                   "gpt-4o-copilot",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  true,
				"name":                  "GPT-4o Copilot",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4o-copilot",
			},
			{
				"capabilities": gin.H{
					"family": "text-embedding-ada-002",
					"limits": gin.H{
						"max_inputs": 512,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{},
					"tokenizer": "cl100k_base",
					"type":      "embeddings",
				},
				"id":                   "text-embedding-ada-002",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "Embedding V2 Ada",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "text-embedding-3-small",
			},
			{
				"capabilities": gin.H{
					"family": "text-embedding-3-small",
					"limits": gin.H{
						"max_inputs": 512,
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"dimensions": true},
					"tokenizer": "cl100k_base",
					"type":      "embeddings",
				},
				"id":                   "text-embedding-3-small",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "Embedding V3 small",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "text-embedding-3-small",
			},
			{
				"capabilities": gin.H{
					"family":    "text-embedding-3-small",
					"object":    "model_capabilities",
					"supports":  gin.H{"dimensions": true},
					"tokenizer": "cl100k_base",
					"type":      "embeddings",
				},
				"id":                   "text-embedding-3-small-inference",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "Embedding V3 small (Inference)",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "text-embedding-3-small",
			},
			{
				"capabilities": gin.H{
					"family": "claude-3.5-sonnet",
					"limits": gin.H{
						"max_context_window_tokens": 90000,
						"max_output_tokens":         8192,
						"max_prompt_tokens":         90000,
						"vision": gin.H{
							"max_prompt_image_size": 3145728,
							"max_prompt_images":     1,
							"supported_media_types": []string{"image/jpeg", "image/png", "image/webp"},
						},
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "tool_calls": true, "vision": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "claude-3.5-sonnet",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  true,
				"name":                  "Claude 3.5 Sonnet",
				"object":                "model",
				"policy": gin.H{
					"state": "enabled",
					"terms": "Enable access to the latest Claude 3.5 Sonnet model from Anthropic. [Learn more about how GitHub Copilot serves Claude 3.5 Sonnet](https://docs.github.com/copilot/using-github-copilot/using-claude-sonnet-in-github-copilot).",
				},
				"preview":               false,
				"vendor":                "Anthropic",
				"version":               "claude-3.5-sonnet",
			},
			{
				"capabilities": gin.H{
					"family": "gemini-2.0-flash",
					"limits": gin.H{
						"max_context_window_tokens": 1000000,
						"max_output_tokens":         8192,
						"max_prompt_tokens":         128000,
						"vision": gin.H{
							"max_prompt_image_size": 3145728,
							"max_prompt_images":     1,
							"supported_media_types": []string{"image/jpeg", "image/png", "image/webp", "image/heic", "image/heif"},
						},
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"streaming": true, "vision": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gemini-2.0-flash-001",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  true,
				"name":                  "Gemini 2.0 Flash",
				"object":                "model",
				"policy": gin.H{
					"state": "unconfigured",
					"terms": "Enable access to the latest Gemini models from Google. [Learn more about how GitHub Copilot serves Gemini 2.0 Flash](https://docs.github.com/en/copilot/using-github-copilot/ai-models/using-gemini-flash-in-github-copilot).",
				},
				"preview":               false,
				"vendor":                "Google",
				"version":               "gemini-2.0-flash-001",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4.1",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         16384,
						"max_prompt_tokens":         128000,
						"vision": gin.H{
							"max_prompt_image_size": 3145728,
							"max_prompt_images":     1,
							"supported_media_types": []string{"image/jpeg", "image/png", "image/webp", "image/gif"},
						},
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "structured_outputs": true, "tool_calls": true, "vision": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4.1",
				"is_chat_default":       false,
				"is_chat_fallback":      true,
				"model_picker_enabled":  true,
				"name":                  "GPT-4.1",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4.1-2025-04-14",
			},
			{
				"capabilities": gin.H{
					"family": "gpt-4.1",
					"limits": gin.H{
						"max_context_window_tokens": 128000,
						"max_output_tokens":         16384,
						"max_prompt_tokens":         128000,
						"vision": gin.H{
							"max_prompt_image_size": 3145728,
							"max_prompt_images":     1,
							"supported_media_types": []string{"image/jpeg", "image/png", "image/webp", "image/gif"},
						},
					},
					"object":    "model_capabilities",
					"supports":  gin.H{"parallel_tool_calls": true, "streaming": true, "structured_outputs": true, "tool_calls": true, "vision": true},
					"tokenizer": "o200k_base",
					"type":      "chat",
				},
				"id":                   "gpt-4.1-2025-04-14",
				"is_chat_default":       false,
				"is_chat_fallback":      false,
				"model_picker_enabled":  false,
				"name":                  "GPT-4.1",
				"object":                "model",
				"preview":               false,
				"vendor":                "Azure OpenAI",
				"version":               "gpt-4.1-2025-04-14",
			},
		},
		"object": "list",
	})
}

func CloseIO(c io.Closer) {
	err := c.Close()
	if nil != err {
		log.Println(err)
	}
}
